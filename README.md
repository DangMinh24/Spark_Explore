# Spark_Explore

# Introduction:

In this project, we will explore about Apache SPARK. We will learn what is Apache SPARK, why do we use it, and how to
use it in practical problems

# What is SPARK?

It is a very useful tool for Data Scientists when dealing with Big Data. SPARK is built on scala, and works in java environment
And it's also supported into python interface

# Why do we want to use SPARK?

Until now, we still confuse about what SPARK actually is. Let imagine SPARK is a library that provide a lot of efficient
tools for user working with Big Data. And what tools can the library provide to us?

It can provide us :

    +SPARK Core: provide a lot of methods that can be calculated efficiently(very fast,faster than python), transformations
from unstructured data into structured data. Provide environment working with clusters and parallel computing (rather than 1
computer deal with big data, we try to split data and divide problem for many computers )

    +SPARK SQL: to query an information in your structured data

    +MLib: provide many algorithms in Machine learning

    +GraphX: provide graphs that you can control your way of computation when working with clusters and parallel computing

    +SPARK Streaming: provide library that help us working with data in real time

Well, It is hard to impress anyone about SPARK with the given information so far. Now we come to practical problems when we use SPARK:

For anyone who want to learn a new algorithm, new Machine Learning technique, a reasonable size data is enough. But when
you want to work with Big data, which may have size 100GB, 1TB, 100TB,..., one laptop/computer may not handle that job.
We can share this job for 100 computers, and then again save it into some Database.

# How to use SPARK?

In this project, we will learn about some concept in SPARK, working with SPARK Core, StreamSPARK, SQLSPARK, some experiment with MLib

